# Извлечение слов

!!! info ""
    **ruts.extractors.WordsExtractor**

## Описание

Модуль для извлечения слов из текста. Позволяет использовать различные токенизаторы, фильтровать стоп-слова, числа и знаки препинания, проводить лемматизацию, формировать N-граммы, а также настраивать минимальную и максимальную длину извлекаемых слов.

!!! note "Примечание"
    В качестве токенизитора по умолчанию используется функция `tokenize` из библиотеки [razdel](https://github.com/natasha/razdel).

!!! note "Примечание"
    В качестве морфологического анализитора для лемматизации по умолчанию используется класс `MorphAnalyzer` из библиотеки [pymorphy2](https://github.com/kmike/pymorphy2).

## Параметры

| Параметр | Тип | По умолчанию | Описание |
| :------: | :-: | :----------: | :------: |
| `tokenizer` | Pattern/Сallable | `None` | Токенизатор или регулярное выражение |
| `filter_punct` | bool | `True` | Фильтровать знаки препинания |
| `filter_nums` | bool | `False` | Фильтровать числа |
| `use_lexemes` | bool | `False` | Использовать леммы слов |
| `stopwords` | List[str] | `None` | Список стоп-слов |
| `lowercase` | bool | `False` | Конвертировать слова в нижний регистр |
| `ngram_range` | Tuple[int, int] | `(1, 1)` | Нижняя и верхняя граница размера N-грамм |
| `min_len` | int | `0` | Минимальная длина извлекаемого слова |
| `max_len` | int | `0` | Максимальная длина извлекаемого слова |

## Методы

### extract

Выполняет извлечение слов из текста.

| Параметр | Тип | По умолчанию | Описание |
| :------: | :-: | :----------: | :------: |
| `text` | str | `-` | Строка текста |

Рассмотрим пример извлечения слов, используя в качестве токенов биграммы, а также выполнив предварительную фильтрацию стоп-слов и лемматизацию:

!!! example "Пример"

    _Код_:

    ``` python
    # Загрузка библиотек
    import re
    from nltk.corpus import stopwords
    from ruts import WordsExtractor

    # Подготовка данных
    text = "Не имей 100 рублей, а имей 100 друзей"

    # Извлечение предложений
    we = WordsExtractor(
        use_lexemes=True,
        stopwords=stopwords.words('russian'),
        filter_nums=True,
        ngram_range=(1, 2)
    )
    we.extract(text)
    ```

    _Результат_:

    ``` bash
    ('иметь', 'рубль', 'иметь', 'друг', 'иметь_рубль', 'рубль_иметь', 'иметь_друг')
    ```

!!! warning "Предупреждение"
    Для корректной работы данного примера необходимо иметь предварительно загруженный список стоп-слов библиотеки [nltk](https://github.com/nltk/nltk) на локальном компьютере. Сделать это можно, выполнив следующий код:

    ``` python
    import nltk
    nltk.download('stopwords')
    ```

### get_most_common

Позволяет получить счетчик топ-слов текста. В качестве параметров принимает количество выводимых топ-слов.

Для иллюстрации работы метода воспользуемся кодом из предыдущего примера:

!!! example "Пример"

    _Код_:

    ``` python
    ...
    
    # Вывод топ-слов
    we.get_most_common(3)
    ```

    _Результат_:

    ``` bash
    [('иметь', 2), ('рубль', 1), ('друг', 1)]
    ```

!!! warning "Предупреждение"
    Для корректной работы метода, он должен вызываться после извлечения слов методом `extract`.